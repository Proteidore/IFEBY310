{
  "hash": "8f33f86e0cc281f3400ad6068e66513c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Introduction to `Spark` RDD\njupyter: python3\n---\n\n::: {#4395ddfd .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\n```\n:::\n\n\n::: {#4186e28d .cell execution_count=2}\n``` {.python .cell-code}\nimport os\nimport sys\nimport inspect\n\nos.environ['PYSPARK_PYTHON'] = sys.executable\nos.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n```\n:::\n\n\n::: {#6c554fd0 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:48:52.492489Z\",\"start_time\":\"2022-01-26T09:48:47.745746Z\"}' execution_count=3}\n``` {.python .cell-code}\nfrom pyspark import SparkConf, SparkContext\n\nconf = SparkConf().setAppName(\"Spark RDD Course\")\nsc = SparkContext(conf=conf)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n25/01/18 14:17:53 WARN Utils: Your hostname, boucheron-Precision-5480 resolves to a loopback address: 127.0.1.1; using 192.168.10.120 instead (on interface wlp0s20f3)\n25/01/18 14:17:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/01/18 14:17:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n```\n:::\n:::\n\n\n::: {#206b8771 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:50:15.768694Z\",\"start_time\":\"2022-01-26T09:50:15.760506Z\"}' execution_count=4}\n``` {.python .cell-code}\nrdd = sc.parallelize(range(64))\n```\n:::\n\n\nNote that `parallelize` takes an optional argument to choose the number of partitions\n\n::: {#2475060d .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:50:16.584063Z\",\"start_time\":\"2022-01-26T09:50:16.578637Z\"}' execution_count=5}\n``` {.python .cell-code}\nrdd.getNumPartitions()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n20\n```\n:::\n:::\n\n\n::: {#1f17c495 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:50:17.040781Z\",\"start_time\":\"2022-01-26T09:50:17.025565Z\"}' execution_count=6}\n``` {.python .cell-code}\nrdd = sc.parallelize(range(1000), 10)\nrdd.getNumPartitions()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n10\n```\n:::\n:::\n\n\n## Transformations\n\n### `map`\n\n::: {#5b65f66d .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:50:26.775706Z\",\"start_time\":\"2022-01-26T09:50:26.766162Z\"}' execution_count=7}\n``` {.python .cell-code}\nrdd = sc.parallelize([2, 3, 4])\nrdd = rdd.map(lambda x: list(range(1, x)))\n```\n:::\n\n\n::: {#9da400ed .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:50:32.871701Z\",\"start_time\":\"2022-01-26T09:50:32.848329Z\"}' execution_count=8}\n``` {.python .cell-code}\nrdd\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nPythonRDD[3] at RDD at PythonRDD.scala:53\n```\n:::\n:::\n\n\n::: {#325c4c39 .cell execution_count=9}\n``` {.python .cell-code}\n(\n    sc.parallelize([2, 3, 4])\n      .map(lambda x: list(range(1, x)))\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nPythonRDD[5] at RDD at PythonRDD.scala:53\n```\n:::\n:::\n\n\n`map` is a *transformation*. It is *lazily* evaluated. Hence execution is delayed until an *action* is met in the DAG).\n\n::: {#e165568d .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:50:52.179698Z\",\"start_time\":\"2022-01-26T09:50:50.637422Z\"}' execution_count=10}\n``` {.python .cell-code}\nrdd.collect()  # collect is an action \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 0:>                                                        (0 + 20) / 20]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n[[1], [1, 2], [1, 2, 3]]\n```\n:::\n:::\n\n\n::: {#2a2d7bd6 .cell execution_count=11}\n``` {.python .cell-code}\n(\n    sc.parallelize([2, 3, 4])\n      .map(lambda x: list(range(1, x)))\n      .collect()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n[[1], [1, 2], [1, 2, 3]]\n```\n:::\n:::\n\n\n### Exercice: `map` with a method\n\n**Warning.** This example is a bad practice !!! Don't do this at home\n\n::: {#f2a54166 .cell execution_count=12}\n``` {.python .cell-code}\ndbtel = {'arthur': 1234, 'riad': 4567, 'anatole': 3615}\n```\n:::\n\n\n::: {#71da9c20 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:53:08.722461Z\",\"start_time\":\"2022-01-26T09:53:08.718705Z\"}' execution_count=13}\n``` {.python .cell-code}\nclass TelephoneDB(object):\n    \n    def __init__(self):\n        self.tel = {'arthur': 1234, 'riad': 4567, 'anatole': 3615}\n   \n    def add_tel(self, name):\n        return name, self.tel.get(name)\n```\n:::\n\n\n::: {#08251851 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:53:09.073597Z\",\"start_time\":\"2022-01-26T09:53:08.885832Z\"}' execution_count=14}\n``` {.python .cell-code}\ntel_db = TelephoneDB()\nnames = ['arthur', 'riad']\n```\n:::\n\n\n::: {#85eecf71 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:53:09.073597Z\",\"start_time\":\"2022-01-26T09:53:08.885832Z\"}' execution_count=15}\n``` {.python .cell-code}\nrdd = sc.parallelize(names).map(tel_db.add_tel).collect()\nrdd\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\n[('arthur', 1234), ('riad', 4567)]\n```\n:::\n:::\n\n\n- Replace the `tel` dictionary by a `defaultdict` with default number `999` \n- Use it on a `rdd` containing names as above including an unknown one, and try it\n\n::: {#4d8ff832 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:53:18.248482Z\",\"start_time\":\"2022-01-26T09:53:18.244348Z\"}' execution_count=16}\n``` {.python .cell-code}\nfrom collections import defaultdict\n\nclass TelephoneDefaultDB(object):\n    \n    def __init__(self):\n        self.tel = defaultdict(lambda: 999, {'arthur': 1234, 'riad': 4567, 'anatole': 3615})\n    \n    def add_tel(self, name):\n        return name, self.tel[name]\n    \n    def add_tel_rdd(self, rdd):  \n        return rdd.map(self.add_tel)\n```\n:::\n\n\n::: {#a2914a2a .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:53:26.542121Z\",\"start_time\":\"2022-01-26T09:53:26.397964Z\"}' execution_count=17}\n``` {.python .cell-code}\ntel_db = TelephoneDefaultDB()\nnames = ['riad', 'anatole', 'yiyang']\nrdd = sc.parallelize(names).map(tel_db.add_tel).collect()\nrdd\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n[('riad', 4567), ('anatole', 3615), ('yiyang', 999)]\n```\n:::\n:::\n\n\n**Warning**. Once again, this is a bad idea to pass *class methods* to spark's `map`.\nSince `add_tel` needs `self`, the whole object is serialized so that `spark` can use it.\nThis breaks if the `tel` is large, or if it is not serializable.\n\n### `flatMap`\n\n::: {#a76a74d3 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:54:17.952337Z\",\"start_time\":\"2022-01-26T09:54:17.822486Z\"}' execution_count=18}\n``` {.python .cell-code}\nrdd = sc.parallelize([2, 3, 4, 5])\nrdd.flatMap(lambda x: range(1, x)).collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n[1, 1, 2, 1, 2, 3, 1, 2, 3, 4]\n```\n:::\n:::\n\n\n### `filter`\n\n::: {#375f21d1 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:54:19.802984Z\",\"start_time\":\"2022-01-26T09:54:19.642499Z\"}' execution_count=19}\n``` {.python .cell-code}\nrdd = sc.parallelize(range(10))\nrdd.filter(lambda x: x % 2 == 0).collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\n[0, 2, 4, 6, 8]\n```\n:::\n:::\n\n\n### `distinct`\n\n::: {#a25194c9 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:55:01.842894Z\",\"start_time\":\"2022-01-26T09:55:00.971479Z\"}' execution_count=20}\n``` {.python .cell-code}\nrdd = sc.parallelize([1, 1, 4, 2, 1, 3, 3])\nrdd.distinct().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\n[1, 2, 3, 4]\n```\n:::\n:::\n\n\n### \"Pseudo-set\" operations\n\n::: {#acd874b3 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:57:28.799644Z\",\"start_time\":\"2022-01-26T09:57:28.539049Z\"}' execution_count=21}\n``` {.python .cell-code}\nrdd1 = sc.parallelize(range(5))\nrdd2 = sc.parallelize(range(3, 9))\nrdd3 = rdd1.union(rdd2)\nrdd3.collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\n[0, 1, 2, 3, 4, 3, 4, 5, 6, 7, 8]\n```\n:::\n:::\n\n\n::: {#9030ca13 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:57:29.358513Z\",\"start_time\":\"2022-01-26T09:57:28.854902Z\"}' execution_count=22}\n``` {.python .cell-code}\nrdd3.distinct().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\n[0, 1, 2, 3, 4, 5, 6, 7, 8]\n```\n:::\n:::\n\n\n::: {#1d84ec49 .cell ExecuteTime='{\"end_time\":\"2022-01-26T09:57:30.724296Z\",\"start_time\":\"2022-01-26T09:57:30.513790Z\"}' execution_count=23}\n``` {.python .cell-code}\nrdd1 = sc.parallelize([1, 2])\nrdd2 = sc.parallelize([\"a\", \"b\"])\nrdd1.cartesian(rdd2).collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\n[(1, 'a'), (1, 'b'), (2, 'a'), (2, 'b')]\n```\n:::\n:::\n\n\n## Actions\n\nWell, `collect` is obviously an action...\n\n### `count`, `countByValue`\n\n::: {#b10a1b5e .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:00:47.366718Z\",\"start_time\":\"2022-01-26T10:00:47.244554Z\"}' execution_count=24}\n``` {.python .cell-code}\nrdd = sc.parallelize([1, 3, 1, 2, 2, 2])\nrdd.count()\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\n6\n```\n:::\n:::\n\n\n::: {#92e324f4 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:00:47.784731Z\",\"start_time\":\"2022-01-26T10:00:47.670195Z\"}' execution_count=25}\n``` {.python .cell-code}\nrdd.countByValue()\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```\ndefaultdict(int, {1: 2, 3: 1, 2: 3})\n```\n:::\n:::\n\n\nWhy does `countByValue()` returns de dictionary?\n\nAre `count()` and `countByValue()` actions or transformations?\n\n::: {#29d08289 .cell execution_count=26}\n``` {.python .cell-code}\nu = np.int32((np.random.sample(100000) * 100000))  # 100000 random integers uniformly distributed on 0, ..., 100000\n\np = (\n    sc.parallelize(u)\n    .countByValue()\n)\n\nq = sorted(p.items(), key = lambda x : x[1], reverse=True)\n\nq[0]\n\n# q[0], 1 + np.log(len(u))/ np.log(np.log(len(u))), len(q)\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\n(np.int32(13647), 8)\n```\n:::\n:::\n\n\n- How many distinct values do you expect in `u` ?\n- How large is the largest value in $q$ ?\n\n::: {#e8826ccb .cell execution_count=27}\n``` {.python .cell-code}\nlen(q), (1-np.exp(-1)) * len(u), 1 + np.log(len(u))/ np.log(np.log(len(u))), np.log(len(u))\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\n(63130,\n np.float64(63212.05588285577),\n np.float64(5.711710714547694),\n np.float64(11.512925464970229))\n```\n:::\n:::\n\n\n### `take`, `takeOrdered`\n\n::: {#acde6c7f .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:01:12.133043Z\",\"start_time\":\"2022-01-26T10:01:12.123139Z\"}' execution_count=28}\n``` {.python .cell-code}\nrdd = sc.parallelize([(3, 'a'), (1, 'b'), (2, 'd')])\n```\n:::\n\n\n::: {#22319eff .cell execution_count=29}\n``` {.python .cell-code}\n(1, 'b') <=  (2, 'd') <= (3, 'a')\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```\nTrue\n```\n:::\n:::\n\n\n::: {#f01f62dd .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:01:12.502110Z\",\"start_time\":\"2022-01-26T10:01:12.368857Z\"}' execution_count=30}\n``` {.python .cell-code}\nrdd.takeOrdered(2)\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\n[(1, 'b'), (2, 'd')]\n```\n:::\n:::\n\n\n::: {#3e74b8c4 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:01:41.658196Z\",\"start_time\":\"2022-01-26T10:01:41.561914Z\"}' execution_count=31}\n``` {.python .cell-code}\nrdd.takeOrdered(2, key=lambda x: x[1])\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\n[(3, 'a'), (1, 'b')]\n```\n:::\n:::\n\n\n### `reduce`, `fold`\n\n::: {#c2388579 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:04:55.619063Z\",\"start_time\":\"2022-01-26T10:04:55.488243Z\"}' execution_count=32}\n``` {.python .cell-code}\nrdd = sc.range(1, 4)\nrdd.reduce(lambda a, b: a + b)\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\n6\n```\n:::\n:::\n\n\n::: {#128a9912 .cell execution_count=33}\n``` {.python .cell-code}\nrdd = sc.range(1, 4, numSlices=7)\nrdd.reduce(lambda a, b: a + b)\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```\n6\n```\n:::\n:::\n\n\n::: {#4eb2a0b9 .cell execution_count=34}\n``` {.python .cell-code}\nrdd = sc.parallelize(range(1,4), 3)\nrdd.reduce(lambda a, b: a + b)\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\n6\n```\n:::\n:::\n\n\n::: {#16b5d9df .cell execution_count=35}\n``` {.python .cell-code}\n( \n    sc.parallelize(range(1, 4), 2)\n      .fold(0, lambda a, b: a + b)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```\n6\n```\n:::\n:::\n\n\n::: {#6110dd41 .cell execution_count=36}\n``` {.python .cell-code}\n( \n    sc.parallelize(range(1, 4), 1)\n      .fold(3, lambda a, b: a + b)\n),( \n    sc.parallelize(range(1, 4), 2)\n      .fold(2, lambda a, b: a + b)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```\n(12, 12)\n```\n:::\n:::\n\n\n::: {#4c1a75f9 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:04:56.257006Z\",\"start_time\":\"2022-01-26T10:04:56.168743Z\"}' execution_count=37}\n``` {.python .cell-code}\nrdd =  sc.parallelize(range(1, 4),3)\nrdd.fold(1, lambda a, b: a + b), rdd.getNumPartitions()\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```\n(10, 3)\n```\n:::\n:::\n\n\n::: {#11ddc3a8 .cell execution_count=38}\n``` {.python .cell-code}\nrdd =  sc.parallelize(range(1, 4),4)\nrdd.fold(1, lambda a, b: a + b), rdd.getNumPartitions()\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\n(11, 4)\n```\n:::\n:::\n\n\n::: {#cc841e67 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:06:13.531030Z\",\"start_time\":\"2022-01-26T10:06:13.468375Z\"}' execution_count=39}\n``` {.python .cell-code}\nrdd = sc.parallelize([1, 2, 4], 2)\nrdd.fold(2, lambda a, b: a + b)\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```\n13\n```\n:::\n:::\n\n\n::: {#27eb4af3 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:06:34.534202Z\",\"start_time\":\"2022-01-26T10:06:34.481600Z\"}' execution_count=40}\n``` {.python .cell-code}\nrdd = sc.parallelize([1, 2, 4], 3)\nrdd.fold(2, lambda a, b: a + b)\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```\n15\n```\n:::\n:::\n\n\n::: {#67e43c6b .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:07:09.860863Z\",\"start_time\":\"2022-01-26T10:07:09.855285Z\"}' execution_count=41}\n``` {.python .cell-code}\nrdd.getNumPartitions()\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```\n3\n```\n:::\n:::\n\n\n### `aggregate`\n\n::: {#9fc9ff79 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:10:45.189587Z\",\"start_time\":\"2022-01-26T10:10:45.103199Z\"}' execution_count=42}\n``` {.python .cell-code}\nseqOp = lambda x, y: (x[0] + y, x[1] + 1)\ncombOp = lambda x, y: (x[0] + y[0], x[1] + y[1])\n\nrdd = sc.parallelize([1, 2, 3, 4], 8)\nrdd.aggregate((0, 0), seqOp, combOp), rdd.getNumPartitions()\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```\n((10, 4), 8)\n```\n:::\n:::\n\n\n::: {#90cc64cc .cell execution_count=43}\n``` {.python .cell-code}\nop = lambda x, y: x+y\nrdd = sc.parallelize([1, 2, 3, 4], 4)\nrdd.aggregate(0, op, op), rdd.getNumPartitions()\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```\n(10, 4)\n```\n:::\n:::\n\n\n### Exercice: sum of powers with `aggregate`\n\n- Using `aggregate`, compute the sum, the sum of squares $x^2$ and the sum of $x^3$ for \n$x \\in \\{1, \\ldots, 10 \\}$.\n- Check your computations using `numpy`\n\n::: {#af9e2682 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:12:45.646275Z\",\"start_time\":\"2022-01-26T10:12:45.642587Z\"}' execution_count=44}\n``` {.python .cell-code}\nseqOp = lambda x, y: (x[0] + y, x[1] + y ** 2, x[2] + y ** 3)\n```\n:::\n\n\n::: {#6941639f .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:12:46.202729Z\",\"start_time\":\"2022-01-26T10:12:46.198959Z\"}' execution_count=45}\n``` {.python .cell-code}\ncombOp = lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2])\n```\n:::\n\n\n::: {#066877fb .cell execution_count=46}\n``` {.python .cell-code}\nsc.range(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```\nPythonRDD[68] at RDD at PythonRDD.scala:53\n```\n:::\n:::\n\n\n::: {#dca07e79 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:12:46.809504Z\",\"start_time\":\"2022-01-26T10:12:46.691691Z\"}' execution_count=47}\n``` {.python .cell-code}\nsc.range(1, 11).aggregate((0, 0, 0), seqOp, combOp)\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```\n(55, 385, 3025)\n```\n:::\n:::\n\n\n::: {#7157eac1 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:13:08.815852Z\",\"start_time\":\"2022-01-26T10:13:08.809493Z\"}' execution_count=48}\n``` {.python .cell-code}\nimport numpy as np\n\nx = np.arange(1, 11)\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```\narray([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n```\n:::\n:::\n\n\n::: {#78d59fcf .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:13:09.313575Z\",\"start_time\":\"2022-01-26T10:13:09.308073Z\"}' execution_count=49}\n``` {.python .cell-code}\nx.sum(), (x**2).sum(), (x**3).sum(), x.cumsum()\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\n(np.int64(55),\n np.int64(385),\n np.int64(3025),\n array([ 1,  3,  6, 10, 15, 21, 28, 36, 45, 55]))\n```\n:::\n:::\n\n\n### Computing an empirical variance with `aggregate`\n\nAssume a sample is stored as a RDD. Using `aggregate`, compute the sample variance $\\frac{1}{n}\\sum_{i=1}^n (x_i - \\overline{X}_n)^2$ where $\\overline{X}_n = \\frac{1}{n} \\sum_{i=1}^n x_i$ \n\n# `PairRDD`\n\n::: {#a0ad56aa .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:32:47.309881Z\",\"start_time\":\"2022-01-26T10:32:47.145371Z\"}' execution_count=50}\n``` {.python .cell-code}\nrdd = sc.parallelize([[1, \"a\", 7], [2, \"b\", 13], [2, \"c\", 17]])\n\nrdd.collect()  # not yet \n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```\n[[1, 'a', 7], [2, 'b', 13], [2, 'c', 17]]\n```\n:::\n:::\n\n\n::: {#aa48d7ad .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:32:47.309881Z\",\"start_time\":\"2022-01-26T10:32:47.145371Z\"}' execution_count=51}\n``` {.python .cell-code}\nrdd = rdd.map(lambda x: (x[0], x[1:]))\n\nrdd.collect()  # done \n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\n[(1, ['a', 7]), (2, ['b', 13]), (2, ['c', 17])]\n```\n:::\n:::\n\n\n## Transformations\n\n### `keys`, `values`\n\n::: {#e8e50284 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:33:19.840293Z\",\"start_time\":\"2022-01-26T10:33:19.737836Z\"}' execution_count=52}\n``` {.python .cell-code}\nrdd.keys().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```\n[1, 2, 2]\n```\n:::\n:::\n\n\n::: {#7985a4b7 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:33:21.985283Z\",\"start_time\":\"2022-01-26T10:33:21.884455Z\"}' execution_count=53}\n``` {.python .cell-code}\nrdd.values().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=53}\n```\n[['a', 7], ['b', 13], ['c', 17]]\n```\n:::\n:::\n\n\n**Warning**. All elements must be tuples with two elements (the key and the value)\n\n::: {#bf3fb6ca .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:41:19.297283Z\",\"start_time\":\"2022-01-26T10:41:19.170242Z\"}' execution_count=54}\n``` {.python .cell-code}\nrdd = sc.parallelize([[1, \"a\", 7], [2, \"b\", 13], [2, \"c\", 17]])\nrdd.keys().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=54}\n```\n[1, 2, 2]\n```\n:::\n:::\n\n\n::: {#a0d755cc .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:41:19.869715Z\",\"start_time\":\"2022-01-26T10:41:19.771203Z\"}' execution_count=55}\n``` {.python .cell-code}\nrdd.values().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```\n['a', 'b', 'c']\n```\n:::\n:::\n\n\nThe values are **not** what we expected wrong... so we **must** do\n\n::: {#f478d133 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:41:21.144124Z\",\"start_time\":\"2022-01-26T10:41:21.029252Z\"}' execution_count=56}\n``` {.python .cell-code}\nrdd = ( sc.parallelize([[1, \"a\", 7], [2, \"b\", 13], [2, \"c\", 17]])\n          .map(lambda x: (x[0], x[1:]))\n      )\nrdd.keys().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=56}\n```\n[1, 2, 2]\n```\n:::\n:::\n\n\n::: {#b742a559 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:41:21.296200Z\",\"start_time\":\"2022-01-26T10:41:21.184436Z\"}' execution_count=57}\n``` {.python .cell-code}\nrdd.values().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```\n[['a', 7], ['b', 13], ['c', 17]]\n```\n:::\n:::\n\n\nNow the values are correct. \n\n### `mapValues`, `flatMapValues`\n\n::: {#8ac52b33 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:41:22.989789Z\",\"start_time\":\"2022-01-26T10:41:22.894772Z\"}' execution_count=58}\n``` {.python .cell-code}\nrdd = sc.parallelize([(\"a\", \"x y z\"), (\"b\", \"p r\")])\n\nrdd.mapValues(lambda v: v.split(' ')).collect(), rdd.collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=58}\n```\n([('a', ['x', 'y', 'z']), ('b', ['p', 'r'])], [('a', 'x y z'), ('b', 'p r')])\n```\n:::\n:::\n\n\n::: {#7fb171c6 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:41:23.311835Z\",\"start_time\":\"2022-01-26T10:41:23.217639Z\"}' execution_count=59}\n``` {.python .cell-code}\nrdd.flatMapValues(lambda v: v.split(' ')).collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=59}\n```\n[('a', 'x'), ('a', 'y'), ('a', 'z'), ('b', 'p'), ('b', 'r')]\n```\n:::\n:::\n\n\n### `groupByKey`\n\n::: {#2e005108 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:41:23.830837Z\",\"start_time\":\"2022-01-26T10:41:23.575739Z\"}' execution_count=60}\n``` {.python .cell-code}\nrdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1), (\"b\", 3), (\"c\", 42)])\n( \n    rdd.groupByKey()\n       .mapValues(list)\n       .collect()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=60}\n```\n[('b', [1, 3]), ('c', [42]), ('a', [1, 1])]\n```\n:::\n:::\n\n\n::: {#1c896314 .cell execution_count=61}\n``` {.python .cell-code}\nrdd.groupByKey().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=61}\n```\n[('b', <pyspark.resultiterable.ResultIterable at 0x7759bdd84bf0>),\n ('c', <pyspark.resultiterable.ResultIterable at 0x7759bdd868a0>),\n ('a', <pyspark.resultiterable.ResultIterable at 0x7759bdd86f30>)]\n```\n:::\n:::\n\n\n### `reduceByKey`\n\n::: {#26c0bd14 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:41:24.139532Z\",\"start_time\":\"2022-01-26T10:41:23.921367Z\"}' execution_count=62}\n``` {.python .cell-code}\nrdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\nrdd.reduceByKey(lambda a, b: a + b).collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=62}\n```\n[('b', 1), ('a', 2)]\n```\n:::\n:::\n\n\n### `combineByKey`\n\n::: {#f00e0957 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:41:24.455934Z\",\"start_time\":\"2022-01-26T10:41:24.224593Z\"}' execution_count=63}\n``` {.python .cell-code}\nrdd = sc.parallelize([('a', 1), ('b', 2), ('a', 13)])\n\ndef add(a, b): \n    return a + str(b)\n\nrdd.combineByKey(str, add, add).collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=63}\n```\n[('b', '2'), ('a', '113')]\n```\n:::\n:::\n\n\n### `join`, `rightOuterJoin`, `leftOuterJoin`\n\n::: {#8a0f5fab .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:46:47.184819Z\",\"start_time\":\"2022-01-26T10:46:47.176731Z\"}' execution_count=64}\n``` {.python .cell-code}\nemployees = sc.parallelize([\n    (31, \"Rafferty\"),\n    (33, \"Jones\"),\n    (33, \"Heisenberg\"),\n    (34, \"Robinson\"),\n    (34, \"Smith\"),\n    (None, \"Williams\")\n])\n```\n:::\n\n\n::: {#7d0af727 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:46:47.380011Z\",\"start_time\":\"2022-01-26T10:46:47.371802Z\"}' execution_count=65}\n``` {.python .cell-code}\ndepartments = sc.parallelize([\n    (31, \"Sales\"),\n    (33, \"Engineering\"),\n    (34, \"Clerical\"),\n    (35, \"Marketing\")\n])\n```\n:::\n\n\n::: {#c5141b5b .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:46:49.996596Z\",\"start_time\":\"2022-01-26T10:46:49.194948Z\"}' execution_count=66}\n``` {.python .cell-code}\nemployees.join(departments).sortByKey().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=66}\n```\n[(31, ('Rafferty', 'Sales')),\n (33, ('Jones', 'Engineering')),\n (33, ('Heisenberg', 'Engineering')),\n (34, ('Robinson', 'Clerical')),\n (34, ('Smith', 'Clerical'))]\n```\n:::\n:::\n\n\n::: {#3af495ed .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:46:01.966800Z\",\"start_time\":\"2022-01-26T10:46:01.121856Z\"}' execution_count=67}\n``` {.python .cell-code}\nemployees.rightOuterJoin(departments).sortByKey().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=67}\n```\n[(31, ('Rafferty', 'Sales')),\n (33, ('Jones', 'Engineering')),\n (33, ('Heisenberg', 'Engineering')),\n (34, ('Robinson', 'Clerical')),\n (34, ('Smith', 'Clerical')),\n (35, (None, 'Marketing'))]\n```\n:::\n:::\n\n\n::: {#fbecb10e .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:46:02.369216Z\",\"start_time\":\"2022-01-26T10:46:01.970100Z\"}' execution_count=68}\n``` {.python .cell-code}\nemployees.leftOuterJoin(departments).collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=68}\n```\n[(None, ('Williams', None)),\n (31, ('Rafferty', 'Sales')),\n (33, ('Jones', 'Engineering')),\n (33, ('Heisenberg', 'Engineering')),\n (34, ('Robinson', 'Clerical')),\n (34, ('Smith', 'Clerical'))]\n```\n:::\n:::\n\n\n## Actions\n\n::: {#60c8b64a .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:47:05.544827Z\",\"start_time\":\"2022-01-26T10:47:05.452900Z\"}' execution_count=69}\n``` {.python .cell-code}\nemployees.countByKey()\n```\n\n::: {.cell-output .cell-output-display execution_count=69}\n```\ndefaultdict(int, {31: 1, 33: 2, 34: 2, None: 1})\n```\n:::\n:::\n\n\n::: {#e5036241 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:47:06.217008Z\",\"start_time\":\"2022-01-26T10:47:06.120690Z\"}' execution_count=70}\n``` {.python .cell-code}\nemployees.lookup(33)\n```\n\n::: {.cell-output .cell-output-display execution_count=70}\n```\n['Jones', 'Heisenberg']\n```\n:::\n:::\n\n\n::: {#d4eb64a1 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:47:29.274325Z\",\"start_time\":\"2022-01-26T10:47:29.191957Z\"}' execution_count=71}\n``` {.python .cell-code}\nemployees.lookup(None)\n```\n\n::: {.cell-output .cell-output-display execution_count=71}\n```\n['Williams']\n```\n:::\n:::\n\n\n::: {#e958fbf7 .cell ExecuteTime='{\"end_time\":\"2022-01-26T10:47:33.540110Z\",\"start_time\":\"2022-01-26T10:47:33.511434Z\"}' execution_count=72}\n``` {.python .cell-code}\nemployees.collectAsMap()\n```\n\n::: {.cell-output .cell-output-display execution_count=72}\n```\n{31: 'Rafferty', 33: 'Heisenberg', 34: 'Smith', None: 'Williams'}\n```\n:::\n:::\n\n\n## References\n\n[Spark Core reference](https://spark.apache.org/docs/3.3.1/api/python/reference/pyspark.html)\n\n",
    "supporting": [
      "notebook05_sparkrdd_files"
    ],
    "filters": [],
    "includes": {}
  }
}