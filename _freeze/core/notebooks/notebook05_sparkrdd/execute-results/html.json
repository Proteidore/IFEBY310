{
  "hash": "3b078cc4edc3d6c7aafdb3667e4155ca",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Introduction to `Spark` RDD\njupyter: python3\n---\n\n::: {#37b5186b .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\n```\n:::\n\n\n::: {#0ae0bb35 .cell execution_count=2}\n``` {.python .cell-code}\nimport os\nimport sys\nimport inspect\n\nos.environ['PYSPARK_PYTHON'] = sys.executable\nos.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n```\n:::\n\n\n::: {#13274ece .cell execution_count=3}\n``` {.python .cell-code}\nfrom pyspark import SparkConf, SparkContext\n\nconf = SparkConf().setAppName(\"Spark RDD Course\")\nsc = SparkContext(conf=conf)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n25/03/10 17:14:14 WARN Utils: Your hostname, boucheron-Precision-5480 resolves to a loopback address: 127.0.1.1; using 172.23.32.10 instead (on interface enxac91a1bd3e89)\n25/03/10 17:14:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/03/10 17:14:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n25/03/10 17:14:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n```\n:::\n:::\n\n\n::: {#e5f1e215 .cell execution_count=4}\n``` {.python .cell-code}\nrdd = sc.parallelize(range(64))\n```\n:::\n\n\nNote that `parallelize` takes an optional argument to choose the number of partitions\n\n::: {#0b1e31d3 .cell execution_count=5}\n``` {.python .cell-code}\nrdd.getNumPartitions()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n20\n```\n:::\n:::\n\n\n::: {#0c4ae2c6 .cell execution_count=6}\n``` {.python .cell-code}\nrdd = sc.parallelize(range(1000), 10)\nrdd.getNumPartitions()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n10\n```\n:::\n:::\n\n\n## Transformations\n\n### `map`\n\n::: {#b9a8cdaa .cell execution_count=7}\n``` {.python .cell-code}\nrdd = sc.parallelize([2, 3, 4])\nrdd = rdd.map(lambda x: list(range(1, x)))\n```\n:::\n\n\n::: {#dfa9853f .cell execution_count=8}\n``` {.python .cell-code}\nrdd\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nPythonRDD[3] at RDD at PythonRDD.scala:53\n```\n:::\n:::\n\n\n::: {#03594e04 .cell execution_count=9}\n``` {.python .cell-code}\n(\n    sc.parallelize([2, 3, 4])\n      .map(lambda x: list(range(1, x)))\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nPythonRDD[5] at RDD at PythonRDD.scala:53\n```\n:::\n:::\n\n\n`map` is a *transformation*. It is *lazily* evaluated. Hence execution is delayed until an *action* is met in the DAG).\n\n::: {#d92cf8b9 .cell execution_count=10}\n``` {.python .cell-code}\nrdd.collect()  # collect is an action \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\r[Stage 0:>                                                        (0 + 20) / 20]\r\r                                                                                \r\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n[[1], [1, 2], [1, 2, 3]]\n```\n:::\n:::\n\n\n::: {#a287ae58 .cell execution_count=11}\n``` {.python .cell-code}\n(\n    sc.parallelize([2, 3, 4])\n      .map(lambda x: list(range(1, x)))\n      .collect()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n[[1], [1, 2], [1, 2, 3]]\n```\n:::\n:::\n\n\n### Exercice: `map` with a method\n\n**Warning.** This example is a bad practice !!! Don't do this at home\n\n::: {#8e3cd989 .cell execution_count=12}\n``` {.python .cell-code}\ndbtel = {'arthur': 1234, 'riad': 4567, 'anatole': 3615}\n```\n:::\n\n\n::: {#a61047d4 .cell execution_count=13}\n``` {.python .cell-code}\nclass TelephoneDB(object):\n    \n    def __init__(self):\n        self.tel = {'arthur': 1234, 'riad': 4567, 'anatole': 3615}\n   \n    def add_tel(self, name):\n        return name, self.tel.get(name)\n```\n:::\n\n\n::: {#cde55ffd .cell execution_count=14}\n``` {.python .cell-code}\ntel_db = TelephoneDB()\nnames = ['arthur', 'riad']\n```\n:::\n\n\n::: {#60ebb441 .cell execution_count=15}\n``` {.python .cell-code}\nrdd = (\n    sc\n        .parallelize(names)\n        .map(tel_db.add_tel)\n        .collect()\n)\n\nrdd\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\n[('arthur', 1234), ('riad', 4567)]\n```\n:::\n:::\n\n\n- Replace the `tel` dictionary by a `defaultdict` with default number `999` \n- Use it on a `rdd` containing names as above including an unknown one, and try it\n\n::: {#229f853d .cell execution_count=16}\n``` {.python .cell-code}\nfrom collections import defaultdict\n\nclass TelephoneDefaultDB(object):\n    \n    def __init__(self):\n        self.tel = defaultdict(lambda: 999, {'arthur': 1234, 'riad': 4567, 'anatole': 3615})\n    \n    def add_tel(self, name):\n        return name, self.tel[name]\n    \n    def add_tel_rdd(self, rdd):  \n        return rdd.map(self.add_tel)\n```\n:::\n\n\n::: {#53dedca2 .cell execution_count=17}\n``` {.python .cell-code}\ntel_db = TelephoneDefaultDB()\nnames = ['riad', 'anatole', 'yiyang']\nrdd = (\n    sc\n        .parallelize(names)\n        .map(tel_db.add_tel)\n        .collect()\n)\nrdd\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n[('riad', 4567), ('anatole', 3615), ('yiyang', 999)]\n```\n:::\n:::\n\n\n::: {.callout-caution}\n\nIt is a bad idea to pass *methods* to spark's `map`.\nSince `add_tel` needs `self`, the whole object is serialized so that `spark` can use it.\n\nThis breaks if the `tel` is large, or if it is not serializable.\n\n:::\n\n### `flatMap`\n\n::: {#f252b2eb .cell execution_count=18}\n``` {.python .cell-code}\nrdd = sc.parallelize([2, 3, 4, 5])\n( \n    rdd\n        .flatMap(lambda x: range(1, x))\n        .collect()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n[1, 1, 2, 1, 2, 3, 1, 2, 3, 4]\n```\n:::\n:::\n\n\n### `filter`\n\n::: {#eb692fa6 .cell execution_count=19}\n``` {.python .cell-code}\nrdd = sc.parallelize(range(10))\n\nrdd\\\n    .filter(lambda x: x % 2 == 0)\\\n    .collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\n[0, 2, 4, 6, 8]\n```\n:::\n:::\n\n\n### `distinct`\n\n::: {#71b6b633 .cell execution_count=20}\n``` {.python .cell-code}\nrdd = sc.parallelize([1, 1, 4, 2, 1, 3, 3])\nrdd.distinct().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\n[1, 2, 3, 4]\n```\n:::\n:::\n\n\n### \"Pseudo-set\" operations\n\n::: {#fc02ef4d .cell execution_count=21}\n``` {.python .cell-code}\nrdd1 = sc.parallelize(range(5))\nrdd2 = sc.parallelize(range(3, 9))\nrdd3 = rdd1.union(rdd2)\nrdd3.collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\n[0, 1, 2, 3, 4, 3, 4, 5, 6, 7, 8]\n```\n:::\n:::\n\n\n::: {#5199c01a .cell execution_count=22}\n``` {.python .cell-code}\nrdd3.distinct().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\n[0, 1, 2, 3, 4, 5, 6, 7, 8]\n```\n:::\n:::\n\n\n::: {#e9f3237f .cell execution_count=23}\n``` {.python .cell-code}\nrdd1 = sc.parallelize([1, 2])\nrdd2 = sc.parallelize([\"a\", \"b\"])\nrdd1.cartesian(rdd2).collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\n[(1, 'a'), (1, 'b'), (2, 'a'), (2, 'b')]\n```\n:::\n:::\n\n\n## Actions\n\n`collect` is obviously an action...\n\n### `count`, `countByValue`\n\n::: {#1e0c0207 .cell execution_count=24}\n``` {.python .cell-code}\nrdd = sc.parallelize([1, 3, 1, 2, 2, 2])\nrdd.count()\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\n6\n```\n:::\n:::\n\n\n::: {#141a6243 .cell execution_count=25}\n``` {.python .cell-code}\nrdd.countByValue()\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```\ndefaultdict(int, {1: 2, 3: 1, 2: 3})\n```\n:::\n:::\n\n\nWhy does `countByValue()` returns a dictionary?\n\nAre `count()` and `countByValue()` actions or transformations?\n\n::: {#687cef96 .cell execution_count=26}\n``` {.python .cell-code}\nu = np.int32((np.random.sample(100000) * 100000))  # 100000 random integers uniformly distributed on 0, ..., 100000\n\np = (\n    sc.parallelize(u)\n    .countByValue()\n)\n\nq = sorted(\n    p.items(), \n    key = lambda x : x[1], \n    reverse=True\n)\n\nq[0:10]\n\nq[0], 1 + np.log(len(u))/ np.log(np.log(len(u))), len(q)\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\n((np.int32(4754), 9), np.float64(5.711710714547694), 63355)\n```\n:::\n:::\n\n\n- How many distinct values do you expect in `u` ?\n- How large is the largest value in $q$ ?\n\n::: {#009bbfd5 .cell execution_count=27}\n``` {.python .cell-code}\nfrom scipy.stats import poisson \n\n( \n    len(q), \n    (1-np.exp(-1)) * len(u),\n    poisson.ppf(1.-1./len(u), 1)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\n(63355, np.float64(63212.05588285577), np.float64(8.0))\n```\n:::\n:::\n\n\n### `take`, `takeOrdered`\n\n::: {#0042b5b0 .cell execution_count=28}\n``` {.python .cell-code}\nrdd = sc.parallelize([(3, 'a'), (1, 'b'), (2, 'd')])\n```\n:::\n\n\n::: {#dfb40cfc .cell execution_count=29}\n``` {.python .cell-code}\n(1, 'b') <=  (2, 'd') <= (3, 'a')\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```\nTrue\n```\n:::\n:::\n\n\n::: {#769966bb .cell execution_count=30}\n``` {.python .cell-code}\nrdd.takeOrdered(2)\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\n[(1, 'b'), (2, 'd')]\n```\n:::\n:::\n\n\n::: {#0c12986c .cell execution_count=31}\n``` {.python .cell-code}\nrdd.takeOrdered(2, key=lambda x: x[1])\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\n[(3, 'a'), (1, 'b')]\n```\n:::\n:::\n\n\n### `reduce`, `fold`\n\n::: {#370abf2f .cell execution_count=32}\n``` {.python .cell-code}\nrdd = sc.range(1, 4)\nrdd.reduce(lambda a, b: a + b)\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\n6\n```\n:::\n:::\n\n\n::: {#d1014f23 .cell execution_count=33}\n``` {.python .cell-code}\nrdd = sc.range(1, 4, numSlices=7)\nrdd.reduce(lambda a, b: a + b)\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```\n6\n```\n:::\n:::\n\n\n::: {#e7510d81 .cell execution_count=34}\n``` {.python .cell-code}\nrdd = sc.parallelize(range(1,4), 3)\nrdd.reduce(lambda a, b: a + b)\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\n6\n```\n:::\n:::\n\n\n::: {#b16f527f .cell execution_count=35}\n``` {.python .cell-code}\n( \n    sc.parallelize(range(1, 4), 2)\n      .fold(0, lambda a, b: a + b)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```\n6\n```\n:::\n:::\n\n\n::: {#2c52da33 .cell execution_count=36}\n``` {.python .cell-code}\n( \n    sc.parallelize(range(1, 4), 1)\n      .fold(3, lambda a, b: a + b)\n),( \n    sc.parallelize(range(1, 4), 2)\n      .fold(2, lambda a, b: a + b)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```\n(12, 12)\n```\n:::\n:::\n\n\n::: {#c34d1899 .cell execution_count=37}\n``` {.python .cell-code}\nrdd =  sc.parallelize(range(1, 4),3)\n( \n    rdd.fold(1, lambda a, b: a + b), \n    rdd.getNumPartitions()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```\n(10, 3)\n```\n:::\n:::\n\n\n::: {#ab8a13b9 .cell execution_count=38}\n``` {.python .cell-code}\nrdd =  sc.parallelize(range(1, 4),4)\n\n(\n    rdd.fold(1, lambda a, b: a + b), \n    rdd.getNumPartitions()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\n(11, 4)\n```\n:::\n:::\n\n\n::: {#480e17d2 .cell execution_count=39}\n``` {.python .cell-code}\nrdd = sc.parallelize([1, 2, 4], 2)\nrdd.fold(2, lambda a, b: a + b)\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```\n13\n```\n:::\n:::\n\n\n::: {#5cc7d9d8 .cell execution_count=40}\n``` {.python .cell-code}\nrdd = sc.parallelize([1, 2, 4], 3)\nrdd.fold(2, lambda a, b: a + b)\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```\n15\n```\n:::\n:::\n\n\n::: {#e366410e .cell execution_count=41}\n``` {.python .cell-code}\nrdd.getNumPartitions()\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```\n3\n```\n:::\n:::\n\n\n### `aggregate`\n\n::: {#2e030a43 .cell execution_count=42}\n``` {.python .cell-code}\nseqOp = lambda x, y: (x[0] + y, x[1] + 1)\ncombOp = lambda x, y: (x[0] + y[0], x[1] + y[1])\n\nrdd = sc.parallelize([1, 2, 3, 4], 8)\n(\n    rdd.aggregate((0, 0), seqOp, combOp), rdd.getNumPartitions()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```\n((10, 4), 8)\n```\n:::\n:::\n\n\n::: {#98e20a71 .cell execution_count=43}\n``` {.python .cell-code}\nop = lambda x, y: x+y\nrdd = sc.parallelize([1, 2, 3, 4], 4)\n(\n    rdd.aggregate(0, op, op),\n    rdd.getNumPartitions()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```\n(10, 4)\n```\n:::\n:::\n\n\n### Exercice: sum of powers with `aggregate`\n\n- Using `aggregate`, compute the sum, the sum of squares $x^2$ and the sum of cubes $x^3$ for \n$x \\in \\{1, \\ldots, 10 \\}$.\n- Check your computations using `numpy`\n\n::: {#73c150dd .cell execution_count=44}\n``` {.python .cell-code}\nseqOp = lambda x, y: (x[0] + y, x[1] + y ** 2, x[2] + y ** 3)\n```\n:::\n\n\n::: {#4b439010 .cell execution_count=45}\n``` {.python .cell-code}\ncombOp = lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2])\n```\n:::\n\n\n::: {#a293f93a .cell execution_count=46}\n``` {.python .cell-code}\nsc.range(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```\nPythonRDD[68] at RDD at PythonRDD.scala:53\n```\n:::\n:::\n\n\n::: {#65e73742 .cell execution_count=47}\n``` {.python .cell-code}\n( \n    sc\n        .range(1, 11)\n        .aggregate((0, 0, 0), seqOp, combOp)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```\n(55, 385, 3025)\n```\n:::\n:::\n\n\n::: {#e029a992 .cell execution_count=48}\n``` {.python .cell-code}\nimport numpy as np\n\nx = np.arange(1, 11)\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```\narray([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n```\n:::\n:::\n\n\n::: {#d9637eb3 .cell execution_count=49}\n``` {.python .cell-code}\nx.sum(), (x**2).sum(), (x**3).sum(), x.cumsum()\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\n(np.int64(55),\n np.int64(385),\n np.int64(3025),\n array([ 1,  3,  6, 10, 15, 21, 28, 36, 45, 55]))\n```\n:::\n:::\n\n\n### Computing an empirical variance with `aggregate`\n\nAssume a sample is stored as a RDD. Using `aggregate`, compute the sample variance $\\frac{1}{n}\\sum_{i=1}^n (x_i - \\overline{X}_n)^2$ where $\\overline{X}_n = \\frac{1}{n} \\sum_{i=1}^n x_i$ \n\n# `PairRDD`\n\n::: {#037eff2f .cell execution_count=50}\n``` {.python .cell-code}\nrdd = sc.parallelize([[1, \"a\", 7], [2, \"b\", 13], [2, \"c\", 17]])\n\nrdd.collect()  # not yet \n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```\n[[1, 'a', 7], [2, 'b', 13], [2, 'c', 17]]\n```\n:::\n:::\n\n\n::: {#cdd4540e .cell execution_count=51}\n``` {.python .cell-code}\nrdd = rdd.map(lambda x: (x[0], x[1:]))\n\nrdd.collect()  # done \n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\n[(1, ['a', 7]), (2, ['b', 13]), (2, ['c', 17])]\n```\n:::\n:::\n\n\n## Transformations\n\n### `keys`, `values`\n\n::: {#f3e14e02 .cell execution_count=52}\n``` {.python .cell-code}\nrdd.keys().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```\n[1, 2, 2]\n```\n:::\n:::\n\n\n::: {#0df329f3 .cell execution_count=53}\n``` {.python .cell-code}\nrdd.values().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=53}\n```\n[['a', 7], ['b', 13], ['c', 17]]\n```\n:::\n:::\n\n\n::: {.callout-warning}\n\nAll elements must be tuples with two elements (key and  value)\n:::\n\n::: {#a0660aee .cell execution_count=54}\n``` {.python .cell-code}\nrdd = sc.parallelize([[1, \"a\", 7], [2, \"b\", 13], [2, \"c\", 17]])\nrdd.keys().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=54}\n```\n[1, 2, 2]\n```\n:::\n:::\n\n\n::: {#1f988138 .cell execution_count=55}\n``` {.python .cell-code}\nrdd.values().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```\n['a', 'b', 'c']\n```\n:::\n:::\n\n\nThe values are *not* what we expected wrong... so we *must* do\n\n::: {#38e8b3b0 .cell execution_count=56}\n``` {.python .cell-code}\nrdd = ( sc.parallelize([[1, \"a\", 7], [2, \"b\", 13], [2, \"c\", 17]])\n          .map(lambda x: (x[0], x[1:]))\n      )\nrdd.keys().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=56}\n```\n[1, 2, 2]\n```\n:::\n:::\n\n\n::: {#04ba6e96 .cell execution_count=57}\n``` {.python .cell-code}\nrdd.values().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```\n[['a', 7], ['b', 13], ['c', 17]]\n```\n:::\n:::\n\n\nNow, the values are correct. \n\n### `mapValues`, `flatMapValues`\n\n::: {#086a387e .cell execution_count=58}\n``` {.python .cell-code}\nrdd = sc.parallelize([(\"a\", \"x y z\"), (\"b\", \"p r\")])\n\nrdd.mapValues(lambda v: v.split(' ')).collect(), rdd.collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=58}\n```\n([('a', ['x', 'y', 'z']), ('b', ['p', 'r'])], [('a', 'x y z'), ('b', 'p r')])\n```\n:::\n:::\n\n\n::: {#6adc5a20 .cell execution_count=59}\n``` {.python .cell-code}\nrdd.flatMapValues(lambda v: v.split(' ')).collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=59}\n```\n[('a', 'x'), ('a', 'y'), ('a', 'z'), ('b', 'p'), ('b', 'r')]\n```\n:::\n:::\n\n\n### `groupByKey`\n\n::: {#5c4184e9 .cell execution_count=60}\n``` {.python .cell-code}\nrdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1), (\"b\", 3), (\"c\", 42)])\n( \n    rdd.groupByKey()\n       .mapValues(list)\n       .collect()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=60}\n```\n[('b', [1, 3]), ('c', [42]), ('a', [1, 1])]\n```\n:::\n:::\n\n\n::: {#0a9be1c5 .cell execution_count=61}\n``` {.python .cell-code}\nrdd.groupByKey().collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=61}\n```\n[('b', <pyspark.resultiterable.ResultIterable at 0x78b9bff47920>),\n ('c', <pyspark.resultiterable.ResultIterable at 0x78b9bff1d610>),\n ('a', <pyspark.resultiterable.ResultIterable at 0x78b9bff478f0>)]\n```\n:::\n:::\n\n\n### `reduceByKey`\n\n::: {#48e9cfea .cell execution_count=62}\n``` {.python .cell-code}\nrdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\nrdd.reduceByKey(lambda a, b: a + b).collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=62}\n```\n[('b', 1), ('a', 2)]\n```\n:::\n:::\n\n\n### `combineByKey`\n\n::: {#2a5d9c1b .cell execution_count=63}\n``` {.python .cell-code}\nrdd = sc.parallelize([('a', 1), ('b', 2), ('a', 13)])\n\ndef add(a, b): \n    return a + str(b)\n\nrdd.combineByKey(str, add, add).collect()\n```\n\n::: {.cell-output .cell-output-display execution_count=63}\n```\n[('b', '2'), ('a', '113')]\n```\n:::\n:::\n\n\n### `join`, `rightOuterJoin`, `leftOuterJoin`\n\n::: {#2316dd0a .cell execution_count=64}\n``` {.python .cell-code}\nemployees = sc.parallelize([\n    (31, \"Rafferty\"),\n    (33, \"Jones\"),\n    (33, \"Heisenberg\"),\n    (34, \"Robinson\"),\n    (34, \"Smith\"),\n    (None, \"Williams\")\n])\n```\n:::\n\n\n::: {#0c4106fc .cell execution_count=65}\n``` {.python .cell-code}\ndepartments = sc.parallelize([\n    (31, \"Sales\"),\n    (33, \"Engineering\"),\n    (34, \"Clerical\"),\n    (35, \"Marketing\")\n])\n```\n:::\n\n\n::: {#8f1a6af0 .cell execution_count=66}\n``` {.python .cell-code}\n( \n    employees\n        .join(departments)\n        .sortByKey()\n        .collect()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=66}\n```\n[(31, ('Rafferty', 'Sales')),\n (33, ('Jones', 'Engineering')),\n (33, ('Heisenberg', 'Engineering')),\n (34, ('Robinson', 'Clerical')),\n (34, ('Smith', 'Clerical'))]\n```\n:::\n:::\n\n\n::: {#6743900f .cell execution_count=67}\n``` {.python .cell-code}\n( \n    employees\n        .rightOuterJoin(departments)\n        .sortByKey()\n        .collect()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=67}\n```\n[(31, ('Rafferty', 'Sales')),\n (33, ('Jones', 'Engineering')),\n (33, ('Heisenberg', 'Engineering')),\n (34, ('Robinson', 'Clerical')),\n (34, ('Smith', 'Clerical')),\n (35, (None, 'Marketing'))]\n```\n:::\n:::\n\n\n::: {#25942d6c .cell execution_count=68}\n``` {.python .cell-code}\n(\n    employees\n        .leftOuterJoin(departments)\n        .collect()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=68}\n```\n[(None, ('Williams', None)),\n (31, ('Rafferty', 'Sales')),\n (33, ('Jones', 'Engineering')),\n (33, ('Heisenberg', 'Engineering')),\n (34, ('Robinson', 'Clerical')),\n (34, ('Smith', 'Clerical'))]\n```\n:::\n:::\n\n\n## Actions\n\n::: {#5183334f .cell execution_count=69}\n``` {.python .cell-code}\nemployees.countByKey()\n```\n\n::: {.cell-output .cell-output-display execution_count=69}\n```\ndefaultdict(int, {31: 1, 33: 2, 34: 2, None: 1})\n```\n:::\n:::\n\n\n::: {#53c51048 .cell execution_count=70}\n``` {.python .cell-code}\nemployees.lookup(33)\n```\n\n::: {.cell-output .cell-output-display execution_count=70}\n```\n['Jones', 'Heisenberg']\n```\n:::\n:::\n\n\n::: {#4c44bd36 .cell execution_count=71}\n``` {.python .cell-code}\nemployees.lookup(None)\n```\n\n::: {.cell-output .cell-output-display execution_count=71}\n```\n['Williams']\n```\n:::\n:::\n\n\n::: {#472fe8ce .cell execution_count=72}\n``` {.python .cell-code}\nemployees.collectAsMap()\n```\n\n::: {.cell-output .cell-output-display execution_count=72}\n```\n{31: 'Rafferty', 33: 'Heisenberg', 34: 'Smith', None: 'Williams'}\n```\n:::\n:::\n\n\n## References\n\n[Spark Core reference](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n\n",
    "supporting": [
      "notebook05_sparkrdd_files"
    ],
    "filters": [],
    "includes": {}
  }
}