{
  "hash": "7d015443bbbf12eae2104c5bfda5941f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ndate: \"2025/01/17 (updated: 2025-01-15)\"\ntitle: \"Python Data Science Stack\"\nengine: knitr\n---\n\n\n\n# What is `Python` ?  {background-color=\"#1c191c\"}\n\n---\n\n<center>\n![](/images/python.png){width=\"40%\"}  \n</center>\n\n- born in 1990\n- designed by Guido van Rossum (BDFL)\n- multi-purpose\n- easy to read\n- easy to learn\n- object-oriented\n- strongly and dynamically typed\n- cross-platform\n\n\n\n# Features of `Python`  {background-color=\"#1c191c\"}\n\n\n## Features of `Python`\n\n\n- High-level data types (`tuples`, `dict`, `list`, `set`, etc.)\n- Standard libraries with batteries included\n  - String services, \n  - Regular expressions\n  - Datetime \n  - ...\n- Libraries for scientific computing\n- Easy and efficient I/O, many file formats\n- OS, threading, multiprocessing\n- Networking, email, html, webserver, scrapping\n- Can be extended with `C/C++` and easily accelerated (`cython`, `numba`, `pypy`)\n- Tons of external libraries\n\n## Features of `Python`\n\n<center>\n![](/images/python_antigravity.png){width=\"45%\"}\n</center>\n\n\n# Trends  {background-color=\"#1c191c\"}\n\n## The [`stackoverflow` 2023 survey](https://survey.stackoverflow.co/2023/)\n\n\n\n<iframe width=\"780\" height=\"500\" src=\"https://survey.stackoverflow.co/2023/#section-most-popular-technologies-programming-scripting-and-markup-languages\" title=\"Stackoverflow survey\"></iframe>\n\n\n## `Python` popularity growth\n\n<center>\n![](/images/python_growth_major_languages.png){width=\"60%\"}\n</center>\n\n\n## `Python` popularity growth\n\n<center>\n![](/images/python_growth_major_languages.png){width=\"75%\"}\n</center>\n\n\n# Why `Python` for  data science ?  {background-color=\"#1c191c\"}\n\n---\n\nBesides these features, `Python` has:\n\n- large communities for data science, analytics, etc.\n- many, well-established, well-documented libraries\n- *huge* demand from the industry\n\n\n\n\n\n# The `Python` Data Science Stack: Maths / Science  {background-color=\"#1c191c\"}\n\n## Numpy\n\n::: {#numpy-scipy}\n\n<center>\n<img src=\"/images/numpy.jpg\" width=28%/>\n<img src=\"\" width=10%/>\n<img src=\"/images/scipy.png\" width=28%/>\n</center>\n\n:::\n\n\n\n{{< contents  numpy-scipy >}}\n\n\n\n\n::: {.fragment .fade-in}\n\n- `numpy` is all about multi-dimensional arrays and matrices\n- high-level computation such as \n  + linear algebra: `numpy.linalg` \n  + random number generation:`numpy.random`\n- Fast but not optimized for multi-threaded architectures\n- Not for distributed multi-machine settings\n\n\n:::\n\n## Scipy\n\n\n\n{{< contents  numpy-scipy >}}\n\n\n\n\n::: {.fragment .fade-in}\n\n- `scipy` extends `numpy` with extra modules:\n  + optimization, \n  + integration, \n  +  FFT, signal and image processing\n  +  ...\n- Sparse matrix formats in `scipy.sparse`\n\n::: \n\n\n\n# The `Python` Data Science Stack: Data processing   {background-color=\"#1c191c\"}\n\n\n## Pandas \n\n\n::: {#pydss-dp}\n\n<center>\n<img src=\"/images/pandas.png\" width=40%/>\n<img src=\"\" width=5%/>\n<img src=\"/images/dask.png\" width=10%/>\n<img src=\"\" width=5%/>\n<img src=\"/images/pyspark.jpg\" width=20%/>\n</center>\n\n:::\n\n\n\n{{< contents pydss-dp >}}\n\n\n\n\n::: {.fragment .fade-in}\n\n- `pandas` builds upon `numpy` to provide a high-performance, easy-to-use `DataFrame` object, with high-level data processing\n- Easy I/O with most data format : `csv`, `json`, `hdf5`, `feather`, `parquet`, etc.\n- `SQL` semantics: `select`, `filter`, `join`, `groupby`, `agg`, , `where`, etc.\n- Very large *general-purpose library for data processing*, not distributed, *medium scale* data only\n\n:::\n\n::: {.fragment .fade-in}\n\n::: {.callout-note title=\"Links\"}\n\n- [Pandas online book](https://wesmckinney.com/book/)\n- [Pandas homepage](https://pandas.pydata.org)\n- [Polars homepage]() \n- [Polars versus Pandas](https://blog.jetbrains.com/pycharm/2024/07/polars-vs-pandas/)\n\n:::\n\n:::\n\n\n## Dask\n\n\n\n{{< contents pydss-dp >}}\n\n\n\n\n::: {.fragment .fade-in}\n\n- `dask` is roughly a *distributed* and *parallel* `pandas`\n- Same API has `pandas` !\n- Task scheduling, lazy evaluation, distributed dataframes\n- Still young and *far behind* `spark`, but can be useful\n- Easier than `spark`, full `Python` (no `JVM`)\n\n:::\n\n::: {.fragment .fade-in}\n\n::: {.callout-note title=\"Links\"}\n\n- [Dask homepage](https://www.dask.org)\n- []()\n\n:::\n\n:::\n\n\n## Pyspark\n\n\n\n{{< contents pydss-dp >}}\n\n\n\n\n::: {.fragment .fade-in}\n\n- `pyspark` is the `python` API to `spark`, a big data processing framework\n- We will use it *a lot* in this course\n- Native API to `spark` is `scala`: `pyspark` can be *slower* (much slower if you are not careful)\n\n:::\n\n::: {.fragment .fade-in}\n\n::: {.callout-note title=\"Links\"}\n\n- [Pyspark documentation](https://spark.apache.org/docs/latest/api/python/index.html)\n- [Spark Apache Project](https://spark.apache.org)\n\n:::\n\n:::\n\n## `SQLAlchemy`\n\n\n\n{{< contents pydss-dp >}}\n\n\n\n\n- Object Relational Model (ORM)\n- ODBC\n  \n\n::: {.fragment .fade-in}\n::: {.callout-note title=\"Links\"}\n\n- [SQl Alchemy homepage](https://www.sqlalchemy.org)\n- [`psycopg2`](https://www.psycopg.org)\n- [psycopg documentation](https://www.psycopg.org/docs/)\n\n:::\n:::\n\n## Pyarrow\n\n\n\n{{< contents pydss-dp >}}\n\n\n\n\n::: {.fragment .fade-in}\n\n> The universal columnar format and multi-language toolbox for fast data interchange and in-memory analytics\n\n> Apache Arrow defines a language-independent columnar memory format for flat and hierarchical data, organized for efficient analytic operations on modern hardware like CPUs and GPUs. The Arrow memory format also supports zero-copy reads for lightning-fast data access without serialization overhead.\n \n:::\n\n::: {.fragment .fade-in}\n::: {.callout-note title=\"Links\"}\n\n- [Apache Arrow Project Homepage](https://arrow.apache.org)\n- [Pyarrow documentation](https://arrow.apache.org/docs/python/index.html)\n\n:::\n:::\n\n\n# The `Python` Data Science Stack: Data Visualization {background-color=\"#1c191c\"}\n\n\n\n## Matplotlib \n\n:::  {#dataviz}\n\n<center>\n\n||||||\n|:-----------|:---:|:---------:|:----:|----------------:|\n|![](/images/matplotlib.png){width=150px}||![](/images/plotly_images.png){width=150px}||![](/images/altair-logo-light.png){width=150px}|\n\n</center>\n\n:::\n\n\n\n{{< contents dataviz >}}\n\n\n\n\n- `matplotlib` provides versatile *2D plotting capabilities*\n  - scientific computing \n  - data visualization\n- Large and customizable library\n- The historical one, somewhat low-level when plotting things related to data\n\n::: {.fragment .fade-in}\n\n::: {.callout-note title=\"Links\"}\n\n[Matplotlib Homepage](https://matplotlib.org)\n\n:::\n:::\n\n\n## Plotly\n\n\n\n{{< contents dataviz >}}\n\n\n\n\n- An **interactive visualization library** for web browsers based on `javascript` graphic library [`d3.js`](https://d3js.org)  \n- With a clean and simple `python` interface, can be used in a `jupyter` notebook\n- Interactions enabled by default (zoom, etc.) and fast rendering\n- Very good looking plots with good default parameters\n\n::: {.fragment .fade-in}\n\n::: {.callout-note title=\"Links\"}\n\n- [Plotly homepage](https://plotly.com)\n\n:::\n\n:::\n\n\n## Altair\n\n\n\n{{< contents dataviz >}}\n\n\n\n\n\n::: {.fragment .fade-in}\n\n> Vega-Altair: Declarative Visualization in Python\n>\n> Vega-Altair is a declarative visualization library for Python. Its simple, friendly and consistent API, built on top of the powerful Vega-Lite grammar, empowers you to spend less time writing code and more time exploring your data.\n\n:::\n\n::: {.fragment .fade-in}\n\n::: {.callout-note title=\"Links\"}\n\n- [Altair homepage](https://altair-viz.github.io)\n- [Vega-Lite: A Grammar of Interactive Graphics](https://vega.github.io/vega-lite/)\n\n:::\n\n:::\n\n\n# The `Python` Data Science Stack: Dashboards {background-color=\"#1c191c\"}\n\n## Dash\n\n\n\n```{=html}\n<iframe width=\"780\" height=\"400\" src=\"https://dash.plotly.com\" title=\"Dash from plotly\"></iframe>\n```\n\n\n\n::: {.callout-note title=\"Links\"}\n\n[Dash homepage](https://dash.plotly.com)\n\n:::\n\n## Shiny\n\n\n\n```{=html}\n<iframe width=\"780\" height=\"400\" src=\"https://shiny.posit.co\" title=\"Shiny\"></iframe>\n```\n\n\n\n::: {.callout-note title=\"Links\"}\n\n[Shiny homepage](https://shiny.posit.co)\n\n:::\n\n# `Python` Data Science Stack: environments  {background-color=\"#1c191c\"}\n\n---\n\n::: {#jupyter}\n\n<img src=\"/images/python.png\" width=35%/>\n<img src=\"\" width=10%/>\n<img src=\"/images/ipython.jpg\" width=20%/>\n<img src=\"\" width=10%/>\n<img src=\"/images/jupyter_logo.png\" width=12%/>\n\n:::\n\n## Pure Python interfaces\n\n\n\n{{< contents jupyter >}}\n\n\n\n\n::: {.fragment .fade-in}\n\nWays to use all these tools\n\n- Write a script `script.py` and use `python` directly in a CLI : `python script.py`\n\n- Use the `ipython` interactive shell\n\n:::\n\n\n## Interfaces : Jupyter\n\n\n\n{{< contents jupyter >}}\n\n\n\n\n::: {.fragment .fade-in}\n\n- Use `jupyter`: a web application that allows to create and run documents, called **notebooks** (with `.ipynb` extension) \n- Notebooks can contain code, equations, visualizations, text, etc. (literate programming)\n- Each `notebook` has a `kernel` running a `python`/`R`,`Julia`, ... thread\n- A **problem**: a `ipynb` file is a `json` document. Leads to bad code diff, a problem with `git` versioning\n\n:::\n\n::: {.fragment .fade-in}\n\n::: {.callout-note title=\"Links\"}\n\n- [jupyter](https://jupyter.org)\n- [jupyterlab](https://jupyterlab.readthedocs.io/en/latest/)\n- [polynote](https://polynote.org/latest/)\n\n:::\n:::\n\n## `Quarto`\n\n\n\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://quarto.org/\" title=\"Quarto homepage\"></iframe>\n```\n\n\n\n\n## Interfaces/IDE : VS Code (and other editors)\n\n\n\n\n```{=html}\n<iframe width=\"780\" height=\"500\" src=\"https://code.visualstudio.com/docs/languages/python\" title=\"VS Code & Python\"></iframe>\n```\n\n\n\n\n# Python and R {background-color=\"#1c191c\"}\n\n## `Reticulate`\n\n::: {.fragment  .fade-in}\n\n> Reticulate embeds a Python session within your R session, enabling seamless, high-performance interoperability. If you are an R developer that uses Python for some of your work or a member of data science team that uses both languages, reticulate can dramatically streamline your workflow!\n\n:::\n\n::: {.fragment  .fade-in}\n\n::: {.callout-note title=\"Links\"}\n\n- [Reticulate homepage](https://rstudio.github.io/reticulate/)\n\n:::\n\n:::\n\n## `Py2R`\n\n::: {.fragment  .fade-in}\n\n> Python has several well-written packages for statistics and data science, but CRAN, R’s central repository, contains thousands of packages implementing sophisticated statistical algorithms that have been field-tested over many years. Thanks to the `rpy2` package, Pythonistas can take advantage of the great work already done by the R community. `rpy2` provides an interface that allows you to run R in Python processes. Users can move between languages and use the best of both programming languages.\n\n:::\n\n\n::: {.fragment  .fade-in}\n\n[rpy2 homepage](https://rpy2.github.io)\n\n:::\n\n\n# But also...  {background-color=\"#1c191c\"}\n\nMany libraries for statistics, machine learning and deep learning\n\n## Statistics \n\n\n\n```{=html}\n<iframe width=\"780\" height=\"400\" src=\"https://www.statsmodels.org/stable/index.html\" title=\"statsmodels package\"></iframe>\n```\n\n\n\n- [`statsmodels`](https://www.statsmodels.org/stable/index.html)\n\n## Machine learning  \n\n- [`scikit-learn`](https://scikit-learn.org/stable/) \n- [`xgboost`](https://xgboost.readthedocs.io/en/stable/) \n- [`lightgbm`](https://lightgbm.readthedocs.io/en/stable/)\n- [`vowpalwabbit`](https://vowpalwabbit.org)\n- ...\n\n## Deep learning\n\n- [`keras`](https://keras.io)\n- [`tensorflow`](https://www.tensorflow.org) \n- [`pytorch`](https://pytorch.org)\n- ...\n\n\n## Getting faster\n\n- `numba`, `cython`, `cupy`\n\n\n\n## And ...  {background-color=\"#1c191c\"}\n\n- `Python` APIs for most databases and clouds\n\n- Processing and plotting tools for Geospatial data\n\n- Image processing\n\n- Web development, web scrapping\n\namong many many many other things...\n\n\n\n# Thank you !  {background-color=\"#1c191c\"}\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}